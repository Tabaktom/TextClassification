{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hExKCzh6doIW"
   },
   "source": [
    "# Lab 4 - Neural Network Classifier Using Simple Word Embeddings\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HixoFOoCIJ7V"
   },
   "source": [
    "In this session, we demonstrate how to solve a text classification task using simple \n",
    "feedforward neural network classifier. We will use IMDB Large Movie Review Dataset to train a binary classification model, able to predict whether a review is positive or negative. First, our network takes one-hot word vectors as input, averages them to make one vector and trains a \n",
    "fully-connected layer to predict the output. In the second part, we replace the one-hot vectors with the word embeddings and add a layer to see how much that improves the performance.\n",
    "\n",
    "We are going to use Keras Sequential API in this session. The Sequential API allows you to make models layer-by-layer. But it is not straightforward to define models where layers connect to more than just the previous and next layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "m8fpBfhBpupy",
    "outputId": "4990ea92-2ff8-480e-959a-7c4f672e2e05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqvPQvgvPv1W"
   },
   "source": [
    "### Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EundMtGPpCdf"
   },
   "source": [
    "The dataset we will be using is the IMDB Large Movie Review Dataset, which consists of 50000 labeled movie reviews. These are split into 25,000 reviews for training and 25,000 reviews for testing. The  dataset contains an even number of positive and negative reviews, so randomly guessing yields 50% accuracy. The data is preprocessed. For text classification, it is ususal to limit the size of the vocabulary to stop the dataset from becoming too sparse, creating possible overfitting. We keep the top 10,000 most frequently occurring words in the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyuSzkafqNca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "imdb = keras.datasets.imdb\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6U4iCV9-rmay"
   },
   "source": [
    "We now can start playing around with the data, letâ€™s first see the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "h-gjWRAuqg5s",
    "outputId": "69fbea39-ff85-4fda-ab0a-32547bed4eb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n",
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(X_train), len(y_train)))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTRZrpcyr-4x"
   },
   "source": [
    "The  reviews have been converted to integers and each integer represents a  word in a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "79Ev72Kgq4XL",
    "outputId": "45015df4-bb43-4ccd-9879-7ca8bfde8bfa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tvuu4KhStqei"
   },
   "source": [
    "We can convert integers back to words by querying a dictionary object that contains the integer to string mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMCH1OoDrSNR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IreFXgruZot"
   },
   "source": [
    "Index 1 represents the beginning of the sentence and the index 2 is assigned to all unknown tokens. Index 0 will be used for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abIb7Fe5u3GQ"
   },
   "outputs": [],
   "source": [
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  \n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9TnnSuspvC5b"
   },
   "source": [
    "To reverse key and values in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKOiVVXQu-_I"
   },
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmTJEm8xvUvW"
   },
   "source": [
    "To view a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SqN5jgVKvJJZ",
    "outputId": "6c2fb60f-7181-40db-a65b-2d334ed3a035"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_index[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6QjrzgVvrYn"
   },
   "source": [
    "And to recreate the whole sentence from our training data we define decode_review:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvrKeMgxvWlv"
   },
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "Sxg4YA_NvdRg",
    "outputId": "e2c2b061-0e2a-46ee-da13-e9494cc4e6c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> french horror cinema has seen something of a revival over the last couple of years with great films such as inside and <UNK> romance <UNK> on to the scene <UNK> <UNK> the revival just slightly but stands head and shoulders over most modern horror titles and is surely one of the best french horror films ever made <UNK> was obviously shot on a low budget but this is made up for in far more ways than one by the originality of the film and this in turn is <UNK> by the excellent writing and acting that ensure the film is a winner the plot focuses on two main ideas prison and black magic the central character is a man named <UNK> sent to prison for fraud he is put in a cell with three others the quietly insane <UNK> body building <UNK> marcus and his retarded boyfriend daisy after a short while in the cell together they stumble upon a hiding place in the wall that contains an old <UNK> after <UNK> part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that <UNK> makes the best of it's <UNK> as despite it's <UNK> the film never actually feels restrained and manages to flow well throughout director eric <UNK> provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell <UNK> that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really <UNK> people and this film proves that as the director <UNK> that we can never really be sure of exactly what is round the corner and this helps to ensure that <UNK> actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall <UNK> is a truly great horror film and one of the best of the decade highly recommended viewing\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(X_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8gIzXncfaJK"
   },
   "source": [
    "### Creating One-hot word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9W4yb3rv_E0"
   },
   "source": [
    "It is  common to use one-hot representation as input in Natural Language Processing tasks. In Keras, the Embedding layer takes an index as an input and convert it to one-hot vector with the length of the vocabulary size. Then multiplies these vectors by a normal weight matrix. But there is no way to only get a one-hot vector as the output of a layer in Keras. To solve this we use Lambda() layer and a function that creates the one-hot layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPO_pK9zH4C5"
   },
   "outputs": [],
   "source": [
    "def OneHot(input_dim=None, input_length=None):\n",
    "    \n",
    "    if input_dim is None or input_length is None:\n",
    "        raise TypeError(\"input_dim or input_length is not set\")\n",
    "\n",
    "    \n",
    "    def _one_hot(x, num_classes):\n",
    "        return K.one_hot(K.cast(x, 'uint8'),\n",
    "                          num_classes=num_classes)\n",
    "\n",
    "    return Lambda(_one_hot,\n",
    "                  arguments={'num_classes': input_dim},\n",
    "                  input_shape=(input_length,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "364d3MAw0ez9"
   },
   "source": [
    "input_dim refers to the length of the one-hot vector and input_length refers to the length of the input sequence. Since the input to K.one_hot should be an integer tensor, we cast x to one (Keras passes around float tensors by default).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHz76GNA2M4r"
   },
   "source": [
    " Each text sequence has in most cases different length of words. Here, we fill sequences with a pad token (0) to fit the size. This special tokens is then masked not to be accounted in averaging, loss calculation etc. We set the maximum length to 256."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9G_o7PsvgSFt"
   },
   "source": [
    "### Preparing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jiFn7sd_wF5j"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_SEQUENCE_LENGTH = 256\n",
    "\n",
    "X_train_enc = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "X_test_enc = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kcjFH1wKF_7d"
   },
   "source": [
    "And to view a padded review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "zwH4dcfW_a18",
    "outputId": "76f17b69-f209-431f-8607-b57be9bbe1a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1  194 1153  194 8255   78  228    5    6 1463 4369 5012  134   26\n",
      "    4  715    8  118 1634   14  394   20   13  119  954  189  102    5\n",
      "  207  110 3103   21   14   69  188    8   30   23    7    4  249  126\n",
      "   93    4  114    9 2300 1523    5  647    4  116    9   35 8163    4\n",
      "  229    9  340 1322    4  118    9    4  130 4901   19    4 1002    5\n",
      "   89   29  952   46   37    4  455    9   45   43   38 1543 1905  398\n",
      "    4 1649   26 6853    5  163   11 3215    2    4 1153    9  194  775\n",
      "    7 8255    2  349 2637  148  605    2 8003   15  123  125   68    2\n",
      " 6853   15  349  165 4362   98    5    4  228    9   43    2 1157   15\n",
      "  299  120    5  120  174   11  220  175  136   50    9 4373  228 8255\n",
      "    5    2  656  245 2350    5    4 9837  131  152  491   18    2   32\n",
      " 7464 1212   14    9    6  371   78   22  625   64 1382    9    8  168\n",
      "  145   23    4 1690   15   16    4 1355    5   28    6   52  154  462\n",
      "   33   89   78  285   16  145   95    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n",
      "(25000, 256)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_enc[1])\n",
    "print(np.shape(X_train_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1zcxFwNGepA"
   },
   "source": [
    "Now we want to build the neural network model. We  are going to have a hidden layer with 16 hidden units. \n",
    "\n",
    "First, we want to transform each index to an embedded vector and then average all vectors to a single one. It has been showed that unweighted average of word vectors outperforms many complicated networks that model semantic and syntactic compositionality. As an example you can take a look at this: (http://anthology.aclweb.org/P/P15/P15-1162.pdf)\n",
    "\n",
    "To average we need to ignore padded zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yi04MLIvJOGZ"
   },
   "outputs": [],
   "source": [
    "class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n",
    "    def call(self, x, mask=None):\n",
    "        if mask != None:\n",
    "            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n",
    "        else:\n",
    "            return super().call(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whgIIB5ggjna"
   },
   "source": [
    "### Neural Network model using one-hot vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jlOLnlnSJgrU"
   },
   "source": [
    "The first layer is an one-hot layer. The second layer is to compute average on all word vectors in a sentence without considering padding. The  output vector is piped through a fully-connected layer. The last layer is connected with a single output node with the sigmoid activation function. The final value is a float between 0 and 1. \n",
    "The vocabulary count of the movie reviews (10000) is used as the input shape. At the end we visualize the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "_Pn83gBbxiK7",
    "outputId": "0c076d9d-7e1b-4359-8e64-8b736c1782ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 256, 10000)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_mas (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 10001     \n",
      "=================================================================\n",
      "Total params: 10,001\n",
      "Trainable params: 10,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=keras.Sequential()\n",
    "model.add(OneHot(VOCAB_SIZE, MAX_SEQUENCE_LENGTH))\n",
    "model.add(GlobalAveragePooling1DMasked())\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Mz96xpCgvTj"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F3HbW_IKLqwT"
   },
   "source": [
    "To compile the model we need a loss function and an optimizer. We use binary_crossentropy loss function which is just a special case of categorical cross entropy. We also use Adam optimizer that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data. You can read more about it here:\n",
    "(https://arxiv.org/abs/1412.6980v8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "colab_type": "code",
    "id": "qh1PWTNMxjUw",
    "outputId": "5ecbc1f6-8b46-491c-b39c-93f765963b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1jwQQqCN5Ia"
   },
   "source": [
    "When training, we want to check the accuracy of the model on data it hasn't seen before. So we create a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5lAqzQlxjSM"
   },
   "outputs": [],
   "source": [
    "X_val = np.array(X_train_enc[:10000])\n",
    "partial_X_train = np.array(X_train_enc[10000:])\n",
    "\n",
    "y_val = np.array(y_train[:10000])\n",
    "partial_y_train = np.array(y_train[10000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E8Kpo5G3OJEY"
   },
   "source": [
    "Then we start to train the model for 40 epochs in mini-batches of 512 samples and monitor the model's loss and accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "99_z39KAxjPi",
    "outputId": "2996d279-9dbe-4ff1-d3ae-16a2a0d4a786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "15000/15000 [==============================] - 7s 490us/step - loss: 0.6930 - acc: 0.5101 - val_loss: 0.6928 - val_acc: 0.4980\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 6s 403us/step - loss: 0.6925 - acc: 0.5129 - val_loss: 0.6924 - val_acc: 0.5244\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 6s 403us/step - loss: 0.6921 - acc: 0.5297 - val_loss: 0.6920 - val_acc: 0.5354\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 6s 403us/step - loss: 0.6917 - acc: 0.5718 - val_loss: 0.6917 - val_acc: 0.5600\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 6s 404us/step - loss: 0.6913 - acc: 0.5864 - val_loss: 0.6913 - val_acc: 0.5818\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 6s 401us/step - loss: 0.6909 - acc: 0.5805 - val_loss: 0.6909 - val_acc: 0.5909\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 6s 404us/step - loss: 0.6905 - acc: 0.5909 - val_loss: 0.6906 - val_acc: 0.6000\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 6s 404us/step - loss: 0.6901 - acc: 0.6469 - val_loss: 0.6901 - val_acc: 0.6545\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 6s 408us/step - loss: 0.6897 - acc: 0.6537 - val_loss: 0.6898 - val_acc: 0.6412\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 6s 407us/step - loss: 0.6893 - acc: 0.6415 - val_loss: 0.6894 - val_acc: 0.6424\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 6s 408us/step - loss: 0.6889 - acc: 0.6556 - val_loss: 0.6890 - val_acc: 0.6511\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 6s 407us/step - loss: 0.6885 - acc: 0.6286 - val_loss: 0.6887 - val_acc: 0.6343\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 6s 410us/step - loss: 0.6881 - acc: 0.6647 - val_loss: 0.6883 - val_acc: 0.6608\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 6s 410us/step - loss: 0.6877 - acc: 0.6682 - val_loss: 0.6879 - val_acc: 0.6602\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 6s 412us/step - loss: 0.6873 - acc: 0.6653 - val_loss: 0.6875 - val_acc: 0.6608\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 6s 411us/step - loss: 0.6869 - acc: 0.6587 - val_loss: 0.6872 - val_acc: 0.6525\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 6s 410us/step - loss: 0.6865 - acc: 0.6697 - val_loss: 0.6868 - val_acc: 0.6651\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 6s 411us/step - loss: 0.6861 - acc: 0.6669 - val_loss: 0.6865 - val_acc: 0.6590\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 6s 413us/step - loss: 0.6857 - acc: 0.6687 - val_loss: 0.6861 - val_acc: 0.6637\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 6s 414us/step - loss: 0.6854 - acc: 0.6736 - val_loss: 0.6858 - val_acc: 0.6637\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 6s 415us/step - loss: 0.6850 - acc: 0.6763 - val_loss: 0.6854 - val_acc: 0.6658\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 6s 415us/step - loss: 0.6846 - acc: 0.6760 - val_loss: 0.6850 - val_acc: 0.6659\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 6s 414us/step - loss: 0.6842 - acc: 0.6735 - val_loss: 0.6847 - val_acc: 0.6657\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 6s 416us/step - loss: 0.6838 - acc: 0.6755 - val_loss: 0.6843 - val_acc: 0.6656\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 6s 415us/step - loss: 0.6835 - acc: 0.6767 - val_loss: 0.6840 - val_acc: 0.6678\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 6s 415us/step - loss: 0.6831 - acc: 0.6738 - val_loss: 0.6837 - val_acc: 0.6650\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 6s 415us/step - loss: 0.6827 - acc: 0.6764 - val_loss: 0.6833 - val_acc: 0.6678\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 6s 416us/step - loss: 0.6823 - acc: 0.6747 - val_loss: 0.6829 - val_acc: 0.6667\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 6s 417us/step - loss: 0.6820 - acc: 0.6767 - val_loss: 0.6826 - val_acc: 0.6683\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 6s 418us/step - loss: 0.6816 - acc: 0.6769 - val_loss: 0.6823 - val_acc: 0.6687\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 6s 418us/step - loss: 0.6812 - acc: 0.6773 - val_loss: 0.6819 - val_acc: 0.6690\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 6s 419us/step - loss: 0.6809 - acc: 0.6769 - val_loss: 0.6816 - val_acc: 0.6699\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 6s 419us/step - loss: 0.6805 - acc: 0.6780 - val_loss: 0.6812 - val_acc: 0.6696\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 6s 419us/step - loss: 0.6801 - acc: 0.6786 - val_loss: 0.6809 - val_acc: 0.6694\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 6s 421us/step - loss: 0.6798 - acc: 0.6783 - val_loss: 0.6806 - val_acc: 0.6712\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 6s 421us/step - loss: 0.6794 - acc: 0.6784 - val_loss: 0.6802 - val_acc: 0.6701\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 6s 422us/step - loss: 0.6790 - acc: 0.6795 - val_loss: 0.6799 - val_acc: 0.6706\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 6s 422us/step - loss: 0.6787 - acc: 0.6791 - val_loss: 0.6795 - val_acc: 0.6733\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 6s 423us/step - loss: 0.6783 - acc: 0.6799 - val_loss: 0.6792 - val_acc: 0.6710\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 6s 424us/step - loss: 0.6780 - acc: 0.6812 - val_loss: 0.6788 - val_acc: 0.6725\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_9a_rybhG5J"
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYLH8kOgOo9W"
   },
   "source": [
    "To evaulate the model on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CFMt2Q7b3taP",
    "outputId": "689fb8c9-e1ea-48b1-ed5b-2d0c90316cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 7s 274us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9RrKiPHcAmQU",
    "outputId": "ee2e81b8-8617-4545-c649-7e90e443a9cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67863190782547, 0.67668]\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "# loss, accuracay "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pW7IpHxMO6qp"
   },
   "source": [
    "Our first model accuracy using one-hot vectors is \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwZk_yoWhPJB"
   },
   "source": [
    "### Plotting the accuracy graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIDPH1J7PMzN"
   },
   "source": [
    "To plot a graph of accuracy and loss over time we can use Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "LS9k2vvSAqB7",
    "outputId": "c69fb429-da72-4e28-af7a-2957cf050c74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a7OwOQw4h8RX"
   },
   "source": [
    "### Neural Network model using word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-QzOMO_P4jc"
   },
   "source": [
    "Now instead of one-hot vectors, we want to use embedding. We change our first layer in model1 to an Embedding layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MFrCsL-NBFVL",
    "outputId": "d3059d4e-8e51-4fb6-deb7-ccb1506f694b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 256, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_mas (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,000,101\n",
      "Trainable params: 1,000,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 1s 36us/step - loss: 0.6894 - acc: 0.6668 - val_loss: 0.6849 - val_acc: 0.7199\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.6781 - acc: 0.7365 - val_loss: 0.6718 - val_acc: 0.7318\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.6605 - acc: 0.7503 - val_loss: 0.6528 - val_acc: 0.7425\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.6369 - acc: 0.7613 - val_loss: 0.6292 - val_acc: 0.7531\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.6093 - acc: 0.7724 - val_loss: 0.6028 - val_acc: 0.7680\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.5793 - acc: 0.7877 - val_loss: 0.5756 - val_acc: 0.7818\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.5489 - acc: 0.8061 - val_loss: 0.5477 - val_acc: 0.7960\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.5191 - acc: 0.8202 - val_loss: 0.5213 - val_acc: 0.8087\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.4907 - acc: 0.8343 - val_loss: 0.4966 - val_acc: 0.8200\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4643 - acc: 0.8447 - val_loss: 0.4741 - val_acc: 0.8284\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4401 - acc: 0.8563 - val_loss: 0.4534 - val_acc: 0.8358\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.4181 - acc: 0.8632 - val_loss: 0.4355 - val_acc: 0.8427\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3982 - acc: 0.8695 - val_loss: 0.4194 - val_acc: 0.8474\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3804 - acc: 0.8762 - val_loss: 0.4050 - val_acc: 0.8533\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3643 - acc: 0.8813 - val_loss: 0.3926 - val_acc: 0.8572\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3499 - acc: 0.8857 - val_loss: 0.3817 - val_acc: 0.8586\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3365 - acc: 0.8903 - val_loss: 0.3716 - val_acc: 0.8635\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3245 - acc: 0.8940 - val_loss: 0.3629 - val_acc: 0.8653\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.3136 - acc: 0.8959 - val_loss: 0.3550 - val_acc: 0.8671\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.3033 - acc: 0.8993 - val_loss: 0.3482 - val_acc: 0.8682\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.2931 - acc: 0.9029 - val_loss: 0.3412 - val_acc: 0.8719\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2841 - acc: 0.9061 - val_loss: 0.3355 - val_acc: 0.8729\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 0s 24us/step - loss: 0.2755 - acc: 0.9088 - val_loss: 0.3305 - val_acc: 0.8744\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 0s 23us/step - loss: 0.2674 - acc: 0.9113 - val_loss: 0.3256 - val_acc: 0.8736\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.2601 - acc: 0.9135 - val_loss: 0.3212 - val_acc: 0.8763\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2527 - acc: 0.9171 - val_loss: 0.3172 - val_acc: 0.8777\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2459 - acc: 0.9203 - val_loss: 0.3135 - val_acc: 0.8791\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.2396 - acc: 0.9209 - val_loss: 0.3111 - val_acc: 0.8782\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2338 - acc: 0.9234 - val_loss: 0.3073 - val_acc: 0.8796\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2276 - acc: 0.9268 - val_loss: 0.3048 - val_acc: 0.8808\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.2224 - acc: 0.9270 - val_loss: 0.3023 - val_acc: 0.8808\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2168 - acc: 0.9296 - val_loss: 0.3002 - val_acc: 0.8813\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2115 - acc: 0.9323 - val_loss: 0.2980 - val_acc: 0.8824\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2066 - acc: 0.9337 - val_loss: 0.2964 - val_acc: 0.8832\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.2020 - acc: 0.9357 - val_loss: 0.2948 - val_acc: 0.8828\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1974 - acc: 0.9381 - val_loss: 0.2935 - val_acc: 0.8843\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1928 - acc: 0.9399 - val_loss: 0.2922 - val_acc: 0.8844\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1887 - acc: 0.9423 - val_loss: 0.2914 - val_acc: 0.8834\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 0s 22us/step - loss: 0.1845 - acc: 0.9445 - val_loss: 0.2899 - val_acc: 0.8838\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 0s 21us/step - loss: 0.1808 - acc: 0.9461 - val_loss: 0.2889 - val_acc: 0.8844\n",
      "25000/25000 [==============================] - 1s 35us/step\n",
      "[0.3032610950279236, 0.87684]\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE= 10000\n",
    "\n",
    "# put the code here\n",
    "\n",
    "model2=keras.Sequential()\n",
    "model2.add(keras.layers.Embedding(VOCAB_SIZE, 100, input_length=256))\n",
    "model2.add(GlobalAveragePooling1DMasked())\n",
    "model2.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model2.summary()\n",
    "\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "X_val = np.array(X_train_enc[:10000])\n",
    "partial_X_train = np.array(X_train_enc[10000:])\n",
    "\n",
    "history2 = model2.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "results = model2.evaluate(X_test_enc, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I4zIPJDcTPq3",
    "outputId": "ddfc7936-9547-4c6a-81e6-19bbc963ca1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 35us/step\n"
     ]
    }
   ],
   "source": [
    "results = model2.evaluate(X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "waS96edDTRyL",
    "outputId": "c4834abb-e945-45f1-e7ec-3916487e2b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3032610950279236, 0.87684]\n"
     ]
    }
   ],
   "source": [
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "XB7aveVzTC5a",
    "outputId": "d61458cd-8b2a-4862-f360-655c8392eaae"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH8Wo9KqwuWZ+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history2.history\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7FBpTc_rXGvQ"
   },
   "source": [
    "The accuracy of model2 is 87%. Using Embedding layer instead of one-hot layer improved the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--020hfG6rN2"
   },
   "source": [
    "### Using pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4gBeOyi4gkM"
   },
   "source": [
    "The Embedding layer can be used to load a pre-trained word embedding model. We are going to use GloVe embeddings, which you can read about it here (https://nlp.stanford.edu/projects/glove/). GloVe stands for \"Global Vectors for Word Representation\". It's a somewhat popular embedding technique based on factorizing a matrix of word co-occurence statistics. You can download GloVe and we can seed the Keras Embedding layer with weights from the pre-trained embedding for the words in your dataset.\n",
    "First, we need to read GloVe and map words to GloVe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_PypdqG9Iis"
   },
   "outputs": [],
   "source": [
    "def readGloveFile(gloveFile):\n",
    "    with open(gloveFile, 'r') as f:\n",
    "        wordToGlove = {}  \n",
    "        wordToIndex = {}  \n",
    "        indexToWord = {}  \n",
    "\n",
    "        for line in f:\n",
    "            record = line.strip().split()\n",
    "            token = record[0] \n",
    "            wordToGlove[token] = np.array(record[1:], dtype=np.float64) \n",
    "            \n",
    "        tokens = sorted(wordToGlove.keys())\n",
    "        for idx, tok in enumerate(tokens):\n",
    "            kerasIdx = idx + 1  \n",
    "            wordToIndex[tok] = kerasIdx \n",
    "            indexToWord[kerasIdx] = tok \n",
    "\n",
    "    return wordToIndex, indexToWord, wordToGlove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZcIZ3dq59bCh"
   },
   "source": [
    "Now, we create our pre-trained Embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gembn7VM3ex8"
   },
   "outputs": [],
   "source": [
    "from keras.initializers import Constant\n",
    "def createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable):\n",
    "    vocabLen = len(wordToIndex) + 1  \n",
    "    embDim = next(iter(wordToGlove.values())).shape[0]  \n",
    "   \n",
    "    embeddingMatrix = np.zeros((vocabLen, embDim))  \n",
    "    for word, index in wordToIndex.items():\n",
    "        embeddingMatrix[index, :] = wordToGlove[word] \n",
    "\n",
    "    embeddingLayer = Embedding(vocabLen, embDim, embeddings_initializer=Constant(embeddingMatrix), trainable=isTrainable)\n",
    "    return embeddingLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGxciLK4-xOr"
   },
   "source": [
    "We freeze the weights. To create the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PZCPUM0W_Drc",
    "outputId": "f62e9ce5-f7e7-44be-c6d9-320f9e1f9e6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-29 12:22:01--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2020-02-29 12:22:02--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2020-02-29 12:22:02--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: â€˜glove.6B.zip.1â€™\n",
      "\n",
      "glove.6B.zip.1      100%[===================>] 822.24M  1.80MB/s    in 6m 28s  \n",
      "\n",
      "2020-02-29 12:28:30 (2.12 MB/s) - â€˜glove.6B.zip.1â€™ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# put the code here\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "etADPpI1UnkG"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "path = 'glove.6B.zip'\n",
    "directory = os.getcwd()\n",
    "zipfile_ = zipfile.ZipFile(path, 'r')\n",
    "zipfile_.extractall(directory)\n",
    "zipfile_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "inoJ9WUMGTkC"
   },
   "outputs": [],
   "source": [
    "wordToIndex, indexToWord, wordToGlove = readGloveFile('glove.6B.100d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-bZ5SCHiIMl"
   },
   "source": [
    "### Adding another hidden layer to the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZbZ6UBDfbjea"
   },
   "source": [
    "In model3, we only add another dense layer to see if that improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "Vw0le1YjDdCa",
    "outputId": "8190ad86-7ab2-4039-986f-4697036fdb6c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
      "  warnings.warn('`Sequential.model` is deprecated. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 100)         40000100  \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_mas (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1616      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 40,001,733\n",
      "Trainable params: 40,001,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "model_glove = keras.Sequential()\n",
    "model_glove.model.add(createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable=True))\n",
    "model_glove.add(GlobalAveragePooling1DMasked())\n",
    "model_glove.add(keras.layers.Dense(16, activation='relu'))\n",
    "model_glove.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model_glove.summary()\n",
    "model_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BWORt_4S2Kr6",
    "outputId": "4c899b56-2889-4296-eec1-115307b6e419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 4s 234us/step - loss: 0.6882 - acc: 0.5452 - val_loss: 0.6834 - val_acc: 0.6047\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.6759 - acc: 0.6389 - val_loss: 0.6689 - val_acc: 0.6455\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.6554 - acc: 0.6763 - val_loss: 0.6452 - val_acc: 0.6824\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.6226 - acc: 0.7125 - val_loss: 0.6078 - val_acc: 0.7214\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 2s 108us/step - loss: 0.5761 - acc: 0.7521 - val_loss: 0.5607 - val_acc: 0.7600\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.5182 - acc: 0.7960 - val_loss: 0.5036 - val_acc: 0.8006\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 2s 108us/step - loss: 0.4574 - acc: 0.8330 - val_loss: 0.4504 - val_acc: 0.8265\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.4022 - acc: 0.8600 - val_loss: 0.4069 - val_acc: 0.8428\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.3577 - acc: 0.8728 - val_loss: 0.3756 - val_acc: 0.8553\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.3233 - acc: 0.8851 - val_loss: 0.3518 - val_acc: 0.8635\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.2960 - acc: 0.8937 - val_loss: 0.3352 - val_acc: 0.8693\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.2723 - acc: 0.9016 - val_loss: 0.3215 - val_acc: 0.8734\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.2509 - acc: 0.9103 - val_loss: 0.3118 - val_acc: 0.8765\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.2332 - acc: 0.9163 - val_loss: 0.3047 - val_acc: 0.8785\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.2155 - acc: 0.9229 - val_loss: 0.2984 - val_acc: 0.8802\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.2011 - acc: 0.9281 - val_loss: 0.2953 - val_acc: 0.8809\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 2s 108us/step - loss: 0.1876 - acc: 0.9336 - val_loss: 0.2919 - val_acc: 0.8815\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.1757 - acc: 0.9390 - val_loss: 0.2916 - val_acc: 0.8838\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.1649 - acc: 0.9450 - val_loss: 0.2909 - val_acc: 0.8831\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.1547 - acc: 0.9499 - val_loss: 0.2922 - val_acc: 0.8848\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.1455 - acc: 0.9547 - val_loss: 0.2936 - val_acc: 0.8858\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 2s 120us/step - loss: 0.1375 - acc: 0.9571 - val_loss: 0.2985 - val_acc: 0.8821\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 0.1295 - acc: 0.9602 - val_loss: 0.2975 - val_acc: 0.8851\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.1223 - acc: 0.9635 - val_loss: 0.3031 - val_acc: 0.8837\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 0.1150 - acc: 0.9655 - val_loss: 0.3069 - val_acc: 0.8817\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 2s 119us/step - loss: 0.1096 - acc: 0.9676 - val_loss: 0.3098 - val_acc: 0.8822\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 2s 119us/step - loss: 0.1030 - acc: 0.9717 - val_loss: 0.3133 - val_acc: 0.8813\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.0971 - acc: 0.9738 - val_loss: 0.3183 - val_acc: 0.8821\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0915 - acc: 0.9747 - val_loss: 0.3232 - val_acc: 0.8817\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0865 - acc: 0.9767 - val_loss: 0.3284 - val_acc: 0.8805\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0815 - acc: 0.9793 - val_loss: 0.3351 - val_acc: 0.8807\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0775 - acc: 0.9811 - val_loss: 0.3416 - val_acc: 0.8796\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.0732 - acc: 0.9834 - val_loss: 0.3479 - val_acc: 0.8791\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0688 - acc: 0.9845 - val_loss: 0.3580 - val_acc: 0.8740\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0656 - acc: 0.9849 - val_loss: 0.3619 - val_acc: 0.8752\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0614 - acc: 0.9861 - val_loss: 0.3674 - val_acc: 0.8760\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0577 - acc: 0.9877 - val_loss: 0.3745 - val_acc: 0.8762\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.0549 - acc: 0.9886 - val_loss: 0.3841 - val_acc: 0.8744\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0514 - acc: 0.9904 - val_loss: 0.3906 - val_acc: 0.8733\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0486 - acc: 0.9911 - val_loss: 0.3970 - val_acc: 0.8738\n",
      "25000/25000 [==============================] - 1s 36us/step\n",
      "[0.42194024595737456, 0.86184]\n"
     ]
    }
   ],
   "source": [
    "X_val = np.array(X_train_enc[:10000])\n",
    "partial_x_train = np.array(X_train_enc[10000:])\n",
    "\n",
    "history_glove= model_glove.fit(partial_x_train, partial_y_train, \n",
    "                               epochs = 40, batch_size =512, \n",
    "                               validation_data=(X_val, y_val), verbose=1)\n",
    "results = model_glove.evaluate(X_test_enc, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "ZWWDctMHPn8k",
    "outputId": "65cd4ac0-4695-4429-eab4-bb1728ab53af"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history_glove.history\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "lcqysZ_nZ9ho",
    "outputId": "cb614a91-33af-492d-fb87-585aa44cba9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86     12500\n",
      "           1       0.86      0.86      0.86     12500\n",
      "\n",
      "    accuracy                           0.86     25000\n",
      "   macro avg       0.86      0.86      0.86     25000\n",
      "weighted avg       0.86      0.86      0.86     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('Test: \\n')\n",
    "test_hat = [round(x[0], 0) for x in model_glove.predict(X_test_enc)]\n",
    "print(classification_report(y_test, test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "KhxOc9kC27Rm",
    "outputId": "8abd4605-32c7-4d08-8b21-cf0c6c0dbd2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
      "  warnings.warn('`Sequential.model` is deprecated. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 100)         40000100  \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_mas (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 40,007,621\n",
      "Trainable params: 40,007,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "model_glove2 = keras.Sequential()\n",
    "model_glove2.model.add(createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable=True))\n",
    "model_glove2.add(GlobalAveragePooling1DMasked())\n",
    "model_glove2.add(keras.layers.Dense(64, activation='relu'))\n",
    "model_glove2.add(keras.layers.Dense(16, activation='relu'))\n",
    "model_glove2.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model_glove2.summary()\n",
    "model_glove2.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jThAWegZ3H9Q",
    "outputId": "1571339a-a258-4164-ec2f-8145b38f988f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 4s 235us/step - loss: 0.6856 - acc: 0.5797 - val_loss: 0.6774 - val_acc: 0.6141\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.6601 - acc: 0.6421 - val_loss: 0.6405 - val_acc: 0.6585\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.6002 - acc: 0.7027 - val_loss: 0.5644 - val_acc: 0.7321\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 2s 113us/step - loss: 0.4995 - acc: 0.7818 - val_loss: 0.4623 - val_acc: 0.8009\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.3952 - acc: 0.8419 - val_loss: 0.3893 - val_acc: 0.8382\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.3285 - acc: 0.8695 - val_loss: 0.3503 - val_acc: 0.8578\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.2796 - acc: 0.8931 - val_loss: 0.3306 - val_acc: 0.8656\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.2456 - acc: 0.9053 - val_loss: 0.3133 - val_acc: 0.8755\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.2145 - acc: 0.9193 - val_loss: 0.3068 - val_acc: 0.8772\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.1916 - acc: 0.9287 - val_loss: 0.3006 - val_acc: 0.8804\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 2s 113us/step - loss: 0.1697 - acc: 0.9391 - val_loss: 0.3060 - val_acc: 0.8783\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 2s 113us/step - loss: 0.1523 - acc: 0.9477 - val_loss: 0.3118 - val_acc: 0.8783\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.1412 - acc: 0.9503 - val_loss: 0.3195 - val_acc: 0.8758\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.1237 - acc: 0.9589 - val_loss: 0.3206 - val_acc: 0.8791\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.1098 - acc: 0.9654 - val_loss: 0.3289 - val_acc: 0.8807\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0990 - acc: 0.9701 - val_loss: 0.3338 - val_acc: 0.8805\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0880 - acc: 0.9756 - val_loss: 0.3473 - val_acc: 0.8797\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 2s 113us/step - loss: 0.0799 - acc: 0.9791 - val_loss: 0.3579 - val_acc: 0.8793\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.0710 - acc: 0.9818 - val_loss: 0.3757 - val_acc: 0.8769\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0648 - acc: 0.9846 - val_loss: 0.3885 - val_acc: 0.8769\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0569 - acc: 0.9878 - val_loss: 0.4018 - val_acc: 0.8751\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0516 - acc: 0.9895 - val_loss: 0.4188 - val_acc: 0.8741\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0455 - acc: 0.9919 - val_loss: 0.4438 - val_acc: 0.8714\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0411 - acc: 0.9931 - val_loss: 0.4509 - val_acc: 0.8720\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.0367 - acc: 0.9939 - val_loss: 0.4663 - val_acc: 0.8700\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0320 - acc: 0.9955 - val_loss: 0.4874 - val_acc: 0.8699\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.0284 - acc: 0.9962 - val_loss: 0.5010 - val_acc: 0.8690\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.0252 - acc: 0.9969 - val_loss: 0.5231 - val_acc: 0.8677\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0225 - acc: 0.9973 - val_loss: 0.5377 - val_acc: 0.8677\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0199 - acc: 0.9977 - val_loss: 0.5596 - val_acc: 0.8663\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0178 - acc: 0.9983 - val_loss: 0.5681 - val_acc: 0.8658\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0159 - acc: 0.9987 - val_loss: 0.5881 - val_acc: 0.8662\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 2s 109us/step - loss: 0.0142 - acc: 0.9985 - val_loss: 0.6021 - val_acc: 0.8625\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 2s 112us/step - loss: 0.0136 - acc: 0.9989 - val_loss: 0.6149 - val_acc: 0.8631\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0122 - acc: 0.9988 - val_loss: 0.6294 - val_acc: 0.8631\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0102 - acc: 0.9992 - val_loss: 0.6445 - val_acc: 0.8632\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 2s 111us/step - loss: 0.0092 - acc: 0.9993 - val_loss: 0.6582 - val_acc: 0.8633\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0082 - acc: 0.9995 - val_loss: 0.6722 - val_acc: 0.8626\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0074 - acc: 0.9996 - val_loss: 0.6838 - val_acc: 0.8625\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 2s 110us/step - loss: 0.0068 - acc: 0.9996 - val_loss: 0.6971 - val_acc: 0.8620\n",
      "25000/25000 [==============================] - 1s 40us/step\n",
      "[0.7517109228301049, 0.84864]\n"
     ]
    }
   ],
   "source": [
    "history_glove2 = model_glove2.fit(partial_x_train, partial_y_train, \n",
    "                                  epochs = 40, batch_size =512, \n",
    "                                  validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "results2 = model_glove2.evaluate(X_test_enc, y_test)\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "QtsdVeW7UgCu",
    "outputId": "a1174426-7704-4828-9dbe-190e84c86011"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history_glove2.history\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "64Q2jHDeTlu0",
    "outputId": "2b313f9f-3860-4d38-9fb4-0669e88a6e76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85     12500\n",
      "           1       0.84      0.86      0.85     12500\n",
      "\n",
      "    accuracy                           0.85     25000\n",
      "   macro avg       0.85      0.85      0.85     25000\n",
      "weighted avg       0.85      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Test: \\n')\n",
    "test_hat = [round(x[0], 0) for x in model_glove2.predict(X_test_enc)]\n",
    "print(classification_report(y_test, test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kx--Ytk3ZbLo"
   },
   "source": [
    "The accuracy of model3 with an additional layer is 85%. Adding more layers can help you to extract more features. But we can do that upto a certain extent. After some point, instead of extracting features, we tend to overfit the data. Overfitting can lead to errors in some or the other form like false positives. It is not easy to choose the number of units in a hidden layer or the number of hidden layers in a neural network. For many applications, one hidden layer is enough. As a general rule, the number of units in that hidden layer is between the number of inputs and the number of outputs.\n",
    " The best way to decide on the number of units and hidden layers is to try various parameters. Train several neural networks with different numbers of hidden layers and neurons, and monitor the performance of them. You will have to experiment using a series of different architectures. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K80OFKxGyBpL"
   },
   "source": [
    "### Looking for improvement: 300D Glove file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "XYC6DykEox2w",
    "outputId": "0bd904fe-e6a0-4287-fab6-463f0274a7cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py:111: UserWarning: `Sequential.model` is deprecated. `Sequential` is a subclass of `Model`, you can just use your `Sequential` instance directly.\n",
      "  warnings.warn('`Sequential.model` is deprecated. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 300)         120000300 \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_mas (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                4816      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 120,005,133\n",
      "Trainable params: 120,005,133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wordToIndex, indexToWord, wordToGlove = readGloveFile('glove.6B.300d.txt')\n",
    "# put your code here\n",
    "model_glove3 = keras.Sequential()\n",
    "model_glove3.model.add(createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable=True))\n",
    "model_glove3.add(GlobalAveragePooling1DMasked())\n",
    "model_glove3.add(keras.layers.Dense(16, activation='relu'))\n",
    "model_glove3.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model_glove3.summary()\n",
    "model_glove3.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GsCJ01StlgCx"
   },
   "source": [
    "This tutorial is substantially based on this document:\n",
    "https://www.tensorflow.org/tutorials/keras/basic_text_classification\n",
    "\n",
    "To read more about Sequential APIs you can go to: https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "The one-hot word vector layer is taken from:\n",
    "https://fdalvi.github.io/blog/2018-04-07-keras-sequential-onehot/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jL0UovfaE9GE",
    "outputId": "b8072928-dc43-4f6b-e361-8db4ac4179d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:421: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 120000300 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 10s 655us/step - loss: 0.6856 - acc: 0.5848 - val_loss: 0.6754 - val_acc: 0.6075\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.6579 - acc: 0.6567 - val_loss: 0.6415 - val_acc: 0.6762\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.6122 - acc: 0.7151 - val_loss: 0.5871 - val_acc: 0.7375\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 5s 307us/step - loss: 0.5392 - acc: 0.7817 - val_loss: 0.5087 - val_acc: 0.7968\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.4543 - acc: 0.8303 - val_loss: 0.4374 - val_acc: 0.8306\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 5s 308us/step - loss: 0.3832 - acc: 0.8602 - val_loss: 0.3859 - val_acc: 0.8486\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.3306 - acc: 0.8785 - val_loss: 0.3522 - val_acc: 0.8610\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.2916 - acc: 0.8939 - val_loss: 0.3318 - val_acc: 0.8646\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 5s 307us/step - loss: 0.2612 - acc: 0.9048 - val_loss: 0.3141 - val_acc: 0.8748\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 5s 308us/step - loss: 0.2361 - acc: 0.9149 - val_loss: 0.3045 - val_acc: 0.8780\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 5s 308us/step - loss: 0.2133 - acc: 0.9250 - val_loss: 0.2991 - val_acc: 0.8776\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.1967 - acc: 0.9307 - val_loss: 0.2971 - val_acc: 0.8817\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 5s 309us/step - loss: 0.1794 - acc: 0.9409 - val_loss: 0.2919 - val_acc: 0.8826\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.1650 - acc: 0.9467 - val_loss: 0.2909 - val_acc: 0.8825\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 5s 307us/step - loss: 0.1520 - acc: 0.9519 - val_loss: 0.2930 - val_acc: 0.8819\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 5s 308us/step - loss: 0.1417 - acc: 0.9568 - val_loss: 0.2947 - val_acc: 0.8830\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 5s 305us/step - loss: 0.1298 - acc: 0.9621 - val_loss: 0.2986 - val_acc: 0.8821\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.1207 - acc: 0.9656 - val_loss: 0.3013 - val_acc: 0.8818\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 5s 305us/step - loss: 0.1114 - acc: 0.9694 - val_loss: 0.3067 - val_acc: 0.8820\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 5s 305us/step - loss: 0.1035 - acc: 0.9723 - val_loss: 0.3125 - val_acc: 0.8805\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.0958 - acc: 0.9749 - val_loss: 0.3218 - val_acc: 0.8761\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 5s 307us/step - loss: 0.0891 - acc: 0.9776 - val_loss: 0.3271 - val_acc: 0.8787\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 5s 305us/step - loss: 0.0827 - acc: 0.9792 - val_loss: 0.3331 - val_acc: 0.8784\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.0765 - acc: 0.9817 - val_loss: 0.3410 - val_acc: 0.8758\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 5s 307us/step - loss: 0.0714 - acc: 0.9838 - val_loss: 0.3514 - val_acc: 0.8741\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.0671 - acc: 0.9851 - val_loss: 0.3586 - val_acc: 0.8739\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 5s 307us/step - loss: 0.0624 - acc: 0.9868 - val_loss: 0.3696 - val_acc: 0.8741\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 5s 305us/step - loss: 0.0571 - acc: 0.9885 - val_loss: 0.3761 - val_acc: 0.8741\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 5s 307us/step - loss: 0.0524 - acc: 0.9907 - val_loss: 0.3853 - val_acc: 0.8745\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.0486 - acc: 0.9924 - val_loss: 0.3952 - val_acc: 0.8731\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 5s 304us/step - loss: 0.0454 - acc: 0.9929 - val_loss: 0.4056 - val_acc: 0.8720\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.0420 - acc: 0.9939 - val_loss: 0.4173 - val_acc: 0.8703\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 5s 304us/step - loss: 0.0392 - acc: 0.9945 - val_loss: 0.4258 - val_acc: 0.8698\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 5s 305us/step - loss: 0.0365 - acc: 0.9952 - val_loss: 0.4346 - val_acc: 0.8688\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.0340 - acc: 0.9955 - val_loss: 0.4452 - val_acc: 0.8688\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 5s 305us/step - loss: 0.0316 - acc: 0.9959 - val_loss: 0.4572 - val_acc: 0.8677\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.0307 - acc: 0.9961 - val_loss: 0.4660 - val_acc: 0.8671\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 5s 307us/step - loss: 0.0272 - acc: 0.9969 - val_loss: 0.4753 - val_acc: 0.8667\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 5s 306us/step - loss: 0.0252 - acc: 0.9973 - val_loss: 0.4858 - val_acc: 0.8663\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 5s 307us/step - loss: 0.0236 - acc: 0.9979 - val_loss: 0.4937 - val_acc: 0.8667\n",
      "25000/25000 [==============================] - 1s 39us/step\n",
      "[0.5246870586776733, 0.85404]\n"
     ]
    }
   ],
   "source": [
    "history_glove3 = model_glove3.fit(partial_x_train, partial_y_train, \n",
    "                                  epochs = 40, batch_size =512, \n",
    "                                  validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "results3 = model_glove3.evaluate(X_test_enc, y_test)\n",
    "print(results3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "Sxua694S1q7g",
    "outputId": "080ff7bc-65c8-4c3e-f12a-527cf7913aaa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwBhjUtz/A5vMpVQRJLlyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history_glove3.history\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blpbmemp2rs0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab4_text_classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
